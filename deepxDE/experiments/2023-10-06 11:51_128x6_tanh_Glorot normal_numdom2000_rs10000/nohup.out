Using backend: pytorch
Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.
paddle supports more examples now and is recommended.
2023-10-06 11:51:21,064 [INFO]: Experiment started.
2023-10-06 11:51:21,064 [INFO]: Configuration: {'TRAINING': {'n_neurons': 128, 'n_layers': 6, 'activation': 'tanh', 'initializer': 'Glorot normal', 'lr_phase1': 0.0005, 'lr_phase2': 0.0005, 'epochs_phase1': 15000, 'epochs_phase2': 150000, 'weights1': [0, 0, 0, 1, 1], 'weights2': [1, 1, 1, 1, 1]}, 'DATA': {'test_size': 0.8, 'num_domain': 2000, 'num_boundary': 1000, 'resampling_period': 10000}, 'path_directory': './experiments/2023-10-06 11:51_128x6_tanh_Glorot normal_numdom2000_rs10000'}
Set the default float type to float64
Device ID: 0, Free Memory: 39410.0 MB
self.triangles shape: (141944, 3)
Compiling model...
'compile' took 0.000191 s

Training model...

Step      Train loss                                            Test loss                                             Test metric
0         [0.00e+00, 0.00e+00, 0.00e+00, 3.63e+03, 3.63e+03]    [0.00e+00, 0.00e+00, 0.00e+00, 3.63e+03, 3.63e+03]    []  
1000      [0.00e+00, 0.00e+00, 0.00e+00, 2.09e+03, 2.09e+03]    [0.00e+00, 0.00e+00, 0.00e+00, 2.09e+03, 2.09e+03]    []  
2000      [0.00e+00, 0.00e+00, 0.00e+00, 2.09e+03, 2.09e+03]    [0.00e+00, 0.00e+00, 0.00e+00, 2.09e+03, 2.09e+03]    []  
3000      [0.00e+00, 0.00e+00, 0.00e+00, 2.09e+03, 2.09e+03]    [0.00e+00, 0.00e+00, 0.00e+00, 2.09e+03, 2.09e+03]    []  
4000      [0.00e+00, 0.00e+00, 0.00e+00, 3.60e+01, 3.60e+01]    [0.00e+00, 0.00e+00, 0.00e+00, 3.60e+01, 3.60e+01]    []  
5000      [0.00e+00, 0.00e+00, 0.00e+00, 1.00e+01, 1.00e+01]    [0.00e+00, 0.00e+00, 0.00e+00, 1.00e+01, 1.00e+01]    []  
6000      [0.00e+00, 0.00e+00, 0.00e+00, 9.15e+00, 9.15e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 9.15e+00, 9.15e+00]    []  
7000      [0.00e+00, 0.00e+00, 0.00e+00, 5.58e+00, 5.58e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 5.58e+00, 5.58e+00]    []  
8000      [0.00e+00, 0.00e+00, 0.00e+00, 3.64e+00, 3.64e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 3.64e+00, 3.64e+00]    []  
9000      [0.00e+00, 0.00e+00, 0.00e+00, 2.35e+00, 2.35e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 2.35e+00, 2.35e+00]    []  
10000     [0.00e+00, 0.00e+00, 0.00e+00, 2.18e+00, 2.18e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 2.18e+00, 2.18e+00]    []  
11000     [0.00e+00, 0.00e+00, 0.00e+00, 1.38e+00, 1.38e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 1.38e+00, 1.38e+00]    []  
12000     [0.00e+00, 0.00e+00, 0.00e+00, 1.15e+00, 1.15e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 1.15e+00, 1.15e+00]    []  
13000     [0.00e+00, 0.00e+00, 0.00e+00, 1.25e+00, 1.25e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 1.25e+00, 1.25e+00]    []  
14000     [0.00e+00, 0.00e+00, 0.00e+00, 1.36e+00, 1.36e+00]    [0.00e+00, 0.00e+00, 0.00e+00, 1.36e+00, 1.36e+00]    []  
15000     [0.00e+00, 0.00e+00, 0.00e+00, 9.75e-01, 9.75e-01]    [0.00e+00, 0.00e+00, 0.00e+00, 9.75e-01, 9.75e-01]    []  

Best model at step 15000:
  train loss: 1.95e+00
  test loss: 1.95e+00
  test metric: []

Epoch 15000: saving model to ./experiments/2023-10-06 11:51_128x6_tanh_Glorot normal_numdom2000_rs10000/model-15000.pt ...

'train' took 7973.459994 s

Saving loss history to ./experiments/2023-10-06 11:51_128x6_tanh_Glorot normal_numdom2000_rs10000/loss.dat ...
Saving training data to ./experiments/2023-10-06 11:51_128x6_tanh_Glorot normal_numdom2000_rs10000/train.dat ...
Saving test data to ./experiments/2023-10-06 11:51_128x6_tanh_Glorot normal_numdom2000_rs10000/test.dat ...
Compiling model...
'compile' took 0.000236 s

Training model...

Step      Train loss                                            Test loss                                             Test metric
15000     [3.06e+01, 4.34e-03, 1.14e-02, 9.75e-01, 9.75e-01]    [3.08e+01, 4.15e-03, 2.22e-03, 9.75e-01, 9.75e-01]    []  
16000     [3.64e-03, 2.09e-04, 1.58e-06, 6.89e-01, 6.89e-01]    [6.34e-03, 2.15e-04, 9.32e-05, 6.89e-01, 6.89e-01]    []  
17000     [1.33e-03, 2.43e-04, 1.17e-06, 7.94e-01, 7.94e-01]    [4.39e-01, 2.67e-04, 5.91e-04, 7.94e-01, 7.94e-01]    []  
18000     [1.10e-03, 2.53e-04, 1.88e-06, 1.40e+00, 1.40e+00]    [3.58e-02, 2.55e-04, 1.19e-03, 1.40e+00, 1.40e+00]    []  
19000     [5.95e-04, 2.55e-04, 2.30e-06, 5.17e-01, 5.17e-01]    [1.00e-01, 2.60e-04, 9.91e-05, 5.17e-01, 5.17e-01]    []  
